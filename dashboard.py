import os
import json
from datetime import datetime, timezone, timedelta
from urllib.parse import urlencode, urlparse, parse_qs, urlunparse
import math

import requests
import pandas as pd
import streamlit as st
from dotenv import load_dotenv
import pydeck as pdk


# =========================
# 0) è®€å– .envï¼ˆèˆ‡æœ¬æª”åŒä¸€å±¤ï¼‰
# =========================
APP_DIR = os.path.dirname(os.path.abspath(__file__))
ENV_PATH = os.path.join(APP_DIR, ".env")
load_dotenv(ENV_PATH)

API_URL = os.getenv("TAICHUNG_MICRO_API_URL", "").strip().strip('"').strip("'")
API_KEY = os.getenv("TAICHUNG_MICRO_API_KEY", "").strip().strip('"').strip("'")

TZ_TW = timezone(timedelta(hours=8))
DATA_DIR = os.path.join(APP_DIR, "data")
CACHE_FILE = os.path.join(DATA_DIR, "taichung_micro_latest.json")

UUID = "33093aab-c094-4caf-9653-389ee511a618"
DEFAULT_SWAGGER_URL = f"https://datacenter.taichung.gov.tw/swagger/OpenData/{UUID}"


# =========================
# å·¥å…·å‡½å¼
# =========================
def ensure_dir(p: str):
    os.makedirs(p, exist_ok=True)


def now_tw():
    return datetime.now(TZ_TW)


def safe_float(x):
    try:
        if x is None:
            return None
        s = str(x).strip()
        if s == "" or s.lower() in ("nan", "none", "null"):
            return None
        return float(s)
    except Exception:
        return None


def normalize_records(payload):
    if payload is None:
        return []
    if isinstance(payload, list):
        return payload
    if isinstance(payload, dict):
        for k in ["records", "data", "items", "result"]:
            v = payload.get(k)
            if isinstance(v, list):
                return v
            if isinstance(v, dict):
                vv = v.get("records")
                if isinstance(vv, list):
                    return vv
    return []


def with_query(url: str, add_params: dict):
    u = urlparse(url)
    q = parse_qs(u.query)
    for k, v in add_params.items():
        if k not in q:
            q[k] = [str(v)]
    new_query = urlencode({k: q[k][0] for k in q}, doseq=False)
    return urlunparse((u.scheme, u.netloc, u.path, u.params, new_query, u.fragment))


def candidate_urls(base_url: str):
    base_url = base_url.strip()
    cands = []
    if base_url:
        cands.append(with_query(base_url, {"limit": 1000, "offset": 0}))
    cands.append(with_query(DEFAULT_SWAGGER_URL, {"limit": 1000, "offset": 0}))
    cands.append(with_query(f"https://datacenter.taichung.gov.tw/OpenData/{UUID}", {"limit": 1000, "offset": 0}))
    cands.append(with_query(f"https://datacenter.taichung.gov.tw/api/OpenData/{UUID}", {"limit": 1000, "offset": 0}))
    cands.append(with_query(f"https://datacenter.taichung.gov.tw/api/v1/OpenData/{UUID}", {"limit": 1000, "offset": 0}))
    cands.append(with_query(f"https://datacenter.taichung.gov.tw/openapi/OpenData/{UUID}", {"limit": 1000, "offset": 0}))

    seen = set()
    uniq = []
    for u in cands:
        if u not in seen:
            uniq.append(u)
            seen.add(u)
    return uniq


def fetch_json(url: str, api_key: str):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                      "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "application/json,text/plain,*/*",
        "Accept-Language": "zh-TW,zh;q=0.9,en;q=0.8",
        "Connection": "close",
        "Cache-Control": "no-cache",
        "Pragma": "no-cache",
    }
    if api_key:
        headers["Authorization"] = api_key
        headers["X-API-KEY"] = api_key

    s = requests.Session()
    r = s.get(url, headers=headers, timeout=35)
    r.raise_for_status()

    try:
        payload = r.json()
    except Exception:
        payload = json.loads(r.text)
    return payload


@st.cache_data(ttl=60)
def fetch_records_smart(base_url: str, api_key: str):
    last_err = None
    tried = []
    for u in candidate_urls(base_url):
        tried.append(u)
        try:
            payload = fetch_json(u, api_key)
            records = normalize_records(payload)
            if isinstance(payload, list) and len(payload) > 0:
                return u, payload
            if records and len(records) > 0:
                return u, records
        except Exception as e:
            last_err = e
            continue

    raise RuntimeError(
        "æ‰€æœ‰å€™é¸ API éƒ½æŠ“ä¸åˆ°è³‡æ–™ã€‚\n"
        f"æœ€å¾ŒéŒ¯èª¤ï¼š{last_err}\n"
        f"å·²å˜—è©¦ï¼š\n- " + "\n- ".join(tried)
    )


def build_df(records):
    if not records:
        return pd.DataFrame()

    df = pd.DataFrame(records).copy()

    candidates = {
        "Device": ["Device", "device", "è¨­å‚™", "è£ç½®"],
        "Town": ["Town", "town", "district", "area", "è¡Œæ”¿å€", "å€", "é„‰é®å¸‚å€"],
        "Landmark": ["Landmark", "landmark", "name", "location", "åœ°æ¨™", "ç«™å", "åœ°é»"],
        "Lat": ["CoordinateLatitude", "latitude", "lat", "CoordinateLat", "Coordinate_Latitude", "ç·¯åº¦"],
        "Lon": ["Coordinatelongitude", "longitude", "lon", "lng", "CoordinateLon", "Coordinate_Longitude", "ç¶“åº¦"],
        "PM25": ["PM2.5", "pm2.5", "pm25", "PM25", "pm2_5", "PM2_5", "ç´°æ‡¸æµ®å¾®ç²’", "PM2_5_UGM3"],
        "Temp": ["Temp", "temp", "temperature", "æº«åº¦", "TEMP"],
        "Hum": ["Hum", "hum", "humidity", "æ¿•åº¦", "HUM"],
        "Id": ["Id", "id"],
    }

    rename = {}
    for std, cands in candidates.items():
        for c in cands:
            if c in df.columns:
                rename[c] = std
                break
    df = df.rename(columns=rename)

    for c in ["Lat", "Lon", "PM25", "Temp", "Hum"]:
        if c in df.columns:
            df[c] = df[c].apply(safe_float)

    return df


def latest_per_device(df):
    if df.empty:
        return df
    if "Device" not in df.columns:
        return df
    return df.drop_duplicates(subset=["Device"], keep="first")


def pm25_level(pm):
    if pm is None:
        return "ç„¡è³‡æ–™"
    if pm <= 15.4: return "è‰¯å¥½"
    if pm <= 35.4: return "æ™®é€š"
    if pm <= 54.4: return "å°æ•æ„Ÿæ—ç¾¤ä¸å¥åº·"
    if pm <= 150.4: return "ä¸å¥åº·"
    if pm <= 250.4: return "éå¸¸ä¸å¥åº·"
    return "å±å®³"


def pm25_advice(level: str):
    if level == "è‰¯å¥½":
        return "å¯æ­£å¸¸æ´»å‹•ã€‚"
    if level == "æ™®é€š":
        return "å¯æ­£å¸¸æ´»å‹•ï¼›æ•æ„Ÿæ—ç¾¤ç•™æ„ã€‚"
    if level == "å°æ•æ„Ÿæ—ç¾¤ä¸å¥åº·":
        return "æ•æ„Ÿæ—ç¾¤æ¸›å°‘é•·æ™‚é–“æˆ¶å¤–æ´»å‹•ã€‚"
    if level == "ä¸å¥åº·":
        return "å»ºè­°æ¸›å°‘æˆ¶å¤–æ´»å‹•ï¼Œå¿…è¦æ™‚æˆ´å£ç½©ã€‚"
    if level == "éå¸¸ä¸å¥åº·":
        return "ç›¡é‡é¿å…å¤–å‡ºï¼›æ•æ„Ÿæ—ç¾¤å»ºè­°ç•™åœ¨å®¤å…§ã€‚"
    if level == "å±å®³":
        return "é¿å…å¤–å‡ºï¼›è‹¥éœ€å¤–å‡ºè«‹åŠ å¼·é˜²è­·ã€‚"
    return "æš«ç„¡å»ºè­°ï¼ˆè³‡æ–™ä¸è¶³ï¼‰ã€‚"


def sensitive_note(level: str):
    if level in ("è‰¯å¥½", "æ™®é€š"):
        return "æ•æ„Ÿæ—ç¾¤ç•™æ„èº«é«”ç‹€æ³"
    if level in ("å°æ•æ„Ÿæ—ç¾¤ä¸å¥åº·", "ä¸å¥åº·", "éå¸¸ä¸å¥åº·", "å±å®³"):
        return "æ•æ„Ÿæ—ç¾¤å»ºè­°æ¸›å°‘æˆ¶å¤–æ´»å‹•"
    return "â€”"


def pm25_color(pm):
    if pm is None:
        return [160, 160, 160, 160]
    if pm <= 15.4:
        return [0, 180, 90, 180]
    if pm <= 35.4:
        return [255, 210, 0, 180]
    if pm <= 54.4:
        return [255, 140, 0, 180]
    if pm <= 150.4:
        return [230, 0, 0, 180]
    if pm <= 250.4:
        return [150, 0, 200, 180]
    return [120, 60, 0, 180]


def pm25_radius(pm, base=60, max_r=260):
    if pm is None:
        return base
    r = base + (pm ** 0.5) * 25
    return min(max_r, max(base, r))


def save_cache(records, used_url: str, fetch_time_str: str):
    ensure_dir(DATA_DIR)
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(
            {"saved_at_tw": fetch_time_str, "used_api": used_url, "count": len(records), "records": records},
            f,
            ensure_ascii=False,
            indent=2,
        )


def citizen_summary(df: pd.DataFrame, fetch_time_str: str):
    if df.empty or "PM25" not in df.columns:
        return {
            "headline": f"ç›®å‰å°šç„¡è¶³å¤ è³‡æ–™å¯åˆ¤è®€ï¼ˆç³»çµ±æŠ“å–æ™‚é–“ï¼š{fetch_time_str}ï¼‰ã€‚",
            "district": "æœªå–å¾— PM2.5 æ¬„ä½æˆ–è³‡æ–™ç‚ºç©ºï¼Œå»ºè­°ç¨å¾Œå†æ›´æ–°ã€‚",
            "howto": "è‹¥ç•«é¢é»ä½å¾ˆå¤šï¼Œå»ºè­°å…ˆé–‹å•Ÿã€Œåªé¡¯ç¤ºè¶…æ¨™é»ä½ã€ã€‚"
        }

    pm = df["PM25"].dropna()
    if pm.empty:
        return {
            "headline": f"ç›®å‰ PM2.5 æš«ç„¡å¯ç”¨æ•¸å€¼ï¼ˆç³»çµ±æŠ“å–æ™‚é–“ï¼š{fetch_time_str}ï¼‰ã€‚",
            "district": "å»ºè­°ç¨å¾Œå†æ›´æ–°ï¼Œæˆ–ç¢ºèªè³‡æ–™æºæ˜¯å¦æ­£å¸¸ã€‚",
            "howto": "å¯åˆ‡æ›åˆ°ã€Œå°ˆæ¥­äººå“¡ç‰ˆã€æŸ¥çœ‹åŸå§‹æ¬„ä½æ˜¯å¦å®Œæ•´ã€‚"
        }

    median = float(pm.median())
    med_level = pm25_level(median)

    if med_level in ("è‰¯å¥½", "æ™®é€š"):
        headline = f"è‡ºä¸­å¸‚æ•´é«”ç©ºå“ä»¥ã€Œ{med_level}ã€ç‚ºä¸»ï¼ˆPM2.5 ä¸­ä½æ•¸ {median:.1f}ï¼‰ã€‚å¤šæ•¸åœ°å€å¯æ­£å¸¸æ´»å‹•ã€‚"
    else:
        headline = f"è‡ºä¸­å¸‚ç›®å‰ç©ºå“åã€Œ{med_level}ã€ï¼ˆPM2.5 ä¸­ä½æ•¸ {median:.1f}ï¼‰ã€‚å»ºè­°æ•æ„Ÿæ—ç¾¤æ¸›å°‘é•·æ™‚é–“æˆ¶å¤–æ´»å‹•ã€‚"

    district_text = ""
    if "Town" in df.columns:
        dd = df[df["Town"].notna() & (df["Town"].astype(str).str.strip() != "")].copy()
        dd = dd[dd["PM25"].notna()]
        if len(dd) > 0:
            g = dd.groupby("Town")["PM25"]
            summary = pd.DataFrame({"æœ€å¤§": g.max(), "å¹³å‡": g.mean(), "é»ä½æ•¸": g.count()}).sort_values(by="æœ€å¤§", ascending=False)
            top3 = summary.head(3)
            lines = [f"- {town}ï¼šæœ€é«˜ {row['æœ€å¤§']:.1f}ï¼ˆå¹³å‡ {row['å¹³å‡']:.1f}ï¼Œé»ä½ {int(row['é»ä½æ•¸'])}ï¼‰"
                     for town, row in top3.iterrows()]
            district_text = "éœ€è¦ç•™æ„çš„è¡Œæ”¿å€ï¼ˆä»¥å€å…§æœ€é«˜ PM2.5 æ’åºï¼‰ï¼š\n" + "\n".join(lines)
        else:
            district_text = "è¡Œæ”¿å€è³‡è¨Šä¸è¶³ï¼Œæš«ä»¥å…¨å¸‚æ•¸å€¼åˆ¤è®€ã€‚"
    else:
        district_text = "è³‡æ–™æœªæä¾›è¡Œæ”¿å€æ¬„ä½ï¼Œæš«ä»¥å…¨å¸‚æ•¸å€¼åˆ¤è®€ã€‚"

    howto = (
        f"æ€éº¼çœ‹é€™å¼µåœ–ï¼š\n"
        f"- ğŸŸ¢ â‰¤15.4ï¼šè‰¯å¥½ã€€ğŸŸ¡ 15.5â€“35.4ï¼šæ™®é€šã€€ğŸŸ  35.5â€“54.4ï¼šæ•æ„Ÿæ—ç¾¤ç•™æ„ã€€ğŸ”´ â‰¥54.5ï¼šä¸å¥åº·\n"
        f"- åœ“é»è¶Šå¤§ä»£è¡¨ PM2.5 è¶Šé«˜ã€‚\n"
        f"- ç³»çµ±æŠ“å–æ™‚é–“ï¼š{fetch_time_str}ï¼ˆæœ¬è³‡æ–™é›†æœªæä¾›è§€æ¸¬æ™‚é–“æˆ³ï¼‰"
    )

    return {"headline": headline, "district": district_text, "howto": howto}


def district_table(df: pd.DataFrame):
    if "Town" not in df.columns or "PM25" not in df.columns:
        return pd.DataFrame()
    dd = df.copy()
    dd = dd[dd["Town"].notna() & (dd["Town"].astype(str).str.strip() != "")]
    dd = dd[dd["PM25"].notna()]
    if dd.empty:
        return pd.DataFrame()
    g = dd.groupby("Town")["PM25"]
    tbl = pd.DataFrame({
        "é»ä½æ•¸": g.count(),
        "å¹³å‡ PM2.5": g.mean().round(1),
        "æœ€å¤§ PM2.5": g.max().round(1),
        "ä¸­ä½æ•¸ PM2.5": g.median().round(1),
    }).sort_values(by="æœ€å¤§ PM2.5", ascending=False)
    return tbl


def district_stats_line(df: pd.DataFrame, town: str):
    if df.empty or "PM25" not in df.columns:
        return "æ­¤è¡Œæ”¿å€ç›®å‰æ²’æœ‰è¶³å¤ è³‡æ–™å¯åˆ¤è®€ã€‚"
    pm = df["PM25"].dropna()
    if pm.empty:
        return "æ­¤è¡Œæ”¿å€ç›®å‰æ²’æœ‰ PM2.5 å¯ç”¨æ•¸å€¼ã€‚"
    n = int(pm.count())
    med = float(pm.median())
    mx = float(pm.max())
    lvl = pm25_level(med)
    msg = f"{town}ç›®å‰æ•´é«”å±¬ã€Œ{lvl}ã€ï¼ˆä¸­ä½æ•¸ {med:.1f}ï¼‰ã€‚{pm25_advice(lvl)}ï¼ˆé»ä½æ•¸ {n}ï¼Œæœ€é«˜ {mx:.1f}ï¼‰"
    return msg


# =========================
# âœ… è‡ªå‹•ç¸®æ”¾ï¼šç”±é»ä½ bounds æ¨ä¼° zoom
# =========================
def clamp(v, lo, hi):
    return max(lo, min(hi, v))


def zoom_from_bounds(lat_min, lat_max, lon_min, lon_max, viewport_px=(1100, 650), padding=1.25):
    lat_span = max(1e-6, lat_max - lat_min)
    lon_span = max(1e-6, lon_max - lon_min)

    def lat_to_mercator_y(lat):
        lat = clamp(lat, -85.0, 85.0)
        rad = math.radians(lat)
        return math.log(math.tan(rad / 2.0 + math.pi / 4.0))

    y_min = lat_to_mercator_y(lat_min)
    y_max = lat_to_mercator_y(lat_max)
    y_span = max(1e-6, y_max - y_min)

    vp_w, vp_h = viewport_px
    scale_x = (vp_w / 256.0) / lon_span
    scale_y = (vp_h / 256.0) / y_span
    scale = min(scale_x, scale_y) / padding

    zoom = math.log(scale, 2)
    return clamp(zoom, 8, 14)


def view_state_for_points(df_map: pd.DataFrame, default_zoom=10):
    m = df_map.dropna(subset=["Lat", "Lon"]).copy()
    if m.empty:
        return pdk.ViewState(latitude=24.15, longitude=120.67, zoom=default_zoom, pitch=0)

    lat_min, lat_max = float(m["Lat"].min()), float(m["Lat"].max())
    lon_min, lon_max = float(m["Lon"].min()), float(m["Lon"].max())

    center_lat = (lat_min + lat_max) / 2.0
    center_lon = (lon_min + lon_max) / 2.0

    if (lat_max - lat_min) < 0.002 and (lon_max - lon_min) < 0.002:
        z = 13
    else:
        z = zoom_from_bounds(lat_min, lat_max, lon_min, lon_max)

    return pdk.ViewState(latitude=center_lat, longitude=center_lon, zoom=z, pitch=0)


# =========================
# UI
# =========================
st.set_page_config(page_title="è‡ºä¸­å¸‚ç©ºå“å¾®ç’°å¢ƒå„€è¡¨æ¿ï¼ˆA2 å¤šé»ä½ï¼‰", layout="wide")
st.title("è‡ºä¸­å¸‚ç©ºå“å¾®ç’°å¢ƒå„€è¡¨æ¿ï¼ˆA2 å¤šé»ä½ï¼‰")
st.caption("è³‡æ–™ä¾†æºï¼šè‡ºä¸­å¸‚æ”¿åºœ OpenDataï¼ˆå¾®å‹æ„Ÿæ¸¬ï¼šPM2.5ï¼æº«åº¦ï¼æ¿•åº¦ï¼ç¶“ç·¯åº¦ï¼‰")

with st.sidebar:
    st.header("é¡¯ç¤ºæ¨¡å¼")
    mode = st.radio("é¸æ“‡ç•«é¢", ["ä¸€èˆ¬æ°‘çœ¾ï¼ˆå¿«é€Ÿç†è§£ï¼‰", "å°ˆæ¥­äººå“¡ï¼ˆå®Œæ•´åˆ†æï¼‰"], index=0)

    st.divider()
    st.header("é€£ç·šè¨­å®š")
    url = st.text_input("API URLï¼ˆå¯ç•™ç©ºï¼‰", value=API_URL)
    api_key = st.text_input("API Keyï¼ˆå¦‚éœ€ï¼Œå·²éš±è—ï¼‰", value=API_KEY, type="password")

    c1, c2 = st.columns(2)
    with c1:
        btn_refresh = st.button("ç«‹å³æ›´æ–°", use_container_width=True)
    with c2:
        btn_clear = st.button("æ¸…é™¤å¿«å–", use_container_width=True)

    if btn_clear:
        st.cache_data.clear()
        st.success("å·²æ¸…é™¤å¿«å–ï¼ˆä¸‹æ¬¡æœƒé‡æ–°æŠ“ï¼‰")

    st.divider()
    st.header("é¡¯ç¤ºé¸é …ï¼ˆå…±ç”¨ï¼‰")
    only_geo = st.checkbox("åªé¡¯ç¤ºæœ‰ç¶“ç·¯åº¦çš„é»ä½", True)
    show_only_exceed = st.checkbox("åªé¡¯ç¤ºè¶…æ¨™é»ä½ï¼ˆPM2.5 > 35.4ï¼‰", False)
    radius_by_pm = st.checkbox("é»ä½åŠå¾‘éš¨ PM2.5 è®ŠåŒ–", True)
    top_n = st.slider("Top Nï¼ˆPM2.5ï¼‰", 10, 200, 50, 10)


# =========================
# å–è³‡æ–™ + æŠ“å–æ™‚é–“
# =========================
fetch_time = now_tw()
fetch_time_str = fetch_time.strftime("%Y-%m-%d %H:%M:%S")

try:
    if btn_refresh:
        st.cache_data.clear()
    used_url, records = fetch_records_smart(url, api_key)
    save_cache(records, used_url, fetch_time_str)
except Exception as e:
    st.error(f"æŠ“å–è³‡æ–™å¤±æ•—ï¼š{e}")
    st.stop()

df_raw = build_df(records)
df = latest_per_device(df_raw)

if df.empty:
    st.warning("è³‡æ–™ç‚ºç©ºï¼ˆæ¬„ä½æ ¼å¼ä¸ç¬¦æˆ–å›å‚³ç©ºé›†åˆï¼‰ã€‚")
    st.stop()

if only_geo and ("Lat" in df.columns) and ("Lon" in df.columns):
    df = df[df["Lat"].notna() & df["Lon"].notna()]

if show_only_exceed and "PM25" in df.columns:
    df = df[df["PM25"].notna() & (df["PM25"] > 35.4)]

dist_tbl = district_table(df)


def render_map(df_map: pd.DataFrame, fit_zoom: bool = False):
    if "Lat" not in df_map.columns or "Lon" not in df_map.columns:
        st.warning("è³‡æ–™ç¼ºå°‘ç¶“ç·¯åº¦ï¼Œç„¡æ³•é¡¯ç¤ºåœ°åœ–ã€‚")
        return
    if df_map[["Lat", "Lon"]].dropna().shape[0] == 0:
        st.warning("ç›®å‰æ²’æœ‰å¯ç”¨çš„ç¶“ç·¯åº¦é»ä½å¯ç•«åœ°åœ–ã€‚")
        return

    m = df_map.copy()
    if "Town" not in m.columns:
        m["Town"] = ""
    if "Landmark" not in m.columns:
        m["Landmark"] = ""
    if "PM25" not in m.columns:
        m["PM25"] = None
    if "Temp" not in m.columns:
        m["Temp"] = None
    if "Hum" not in m.columns:
        m["Hum"] = None

    m["level"] = m["PM25"].apply(pm25_level)
    m["advice"] = m["level"].apply(pm25_advice)
    m["sensitive"] = m["level"].apply(sensitive_note)

    m["color"] = m["PM25"].apply(pm25_color)
    m["radius"] = m["PM25"].apply(lambda x: pm25_radius(x)) if radius_by_pm else 80

    if fit_zoom:
        view_state = view_state_for_points(m, default_zoom=10)
    else:
        view_state = pdk.ViewState(
            latitude=float(m["Lat"].median()),
            longitude=float(m["Lon"].median()),
            zoom=10,
            pitch=0,
        )

    layer = pdk.Layer(
        "ScatterplotLayer",
        data=m,
        get_position=["Lon", "Lat"],
        get_radius="radius",
        get_fill_color="color",
        pickable=True,
        auto_highlight=True,
    )

    tooltip = {
        "text": (
            "{Town}ï½œ{Landmark}\n"
            "PM2.5ï¼š{PM25} Î¼g/mÂ³ï¼ˆ{level}ï¼‰\n"
            "æº«åº¦ï¼š{Temp} Â°Cï½œæ¿•åº¦ï¼š{Hum} %\n"
            "å»ºè­°ï¼š{advice}\n"
            "æ•æ„Ÿæ—ç¾¤ï¼š{sensitive}\n"
            "â€” åˆ†ç´šé–€æª» â€”\n"
            "â‰¤15.4 è‰¯å¥½ï½œ15.5â€“35.4 æ™®é€šï½œ35.5â€“54.4 æ•æ„Ÿæ—ç¾¤ï½œâ‰¥54.5 ä¸å¥åº·"
        )
    }

    deck = pdk.Deck(
        map_style=None,
        initial_view_state=view_state,
        layers=[layer],
        tooltip=tooltip,
    )
    st.pydeck_chart(deck, use_container_width=True)


# =========================
# ç‰ˆé¢ï¼šä¸€èˆ¬æ°‘çœ¾ vs å°ˆæ¥­äººå“¡
# =========================
if mode == "ä¸€èˆ¬æ°‘çœ¾ï¼ˆå¿«é€Ÿç†è§£ï¼‰":
    st.success("ä½¿ç”¨æ–¹å¼ï¼šå…ˆçœ‹ã€Œå¿«é€Ÿåˆ¤è®€ã€æŠ“é‡é» â†’ å†çœ‹åœ°åœ–å®šä½ï¼›å¯ç”¨ä¸‹æ‹‰é¸æ“‡è¡Œæ”¿å€èšç„¦æŸ¥çœ‹ï¼›è‹¥åªæƒ³çœ‹éœ€æ³¨æ„åœ°é»ï¼Œå‹¾é¸å·¦å´ã€Œåªé¡¯ç¤ºè¶…æ¨™é»ä½ã€ã€‚")

    summary = citizen_summary(df, fetch_time_str)

    st.subheader("å¿«é€Ÿåˆ¤è®€")
    st.info(summary["headline"])

    left, right = st.columns([1.1, 0.9])
    with left:
        st.markdown("### ä½ éœ€è¦ç•™æ„ä»€éº¼ï¼Ÿ")
        st.markdown(summary["district"])
    with right:
        st.markdown("### çœ‹åœ–å°æŠ„")
        st.markdown(summary["howto"])

    st.divider()

    st.subheader("é¸æ“‡è¡Œæ”¿å€ï¼ˆèšç„¦æŸ¥çœ‹ï¼‰")
    fit_zoom = False

    if "Town" in df.columns:
        town_list = sorted([t for t in df["Town"].dropna().astype(str).unique() if t.strip() != ""])
        options = ["å…¨å¸‚"] + town_list
        selected = st.selectbox("è¡Œæ”¿å€", options, index=0)

        if selected != "å…¨å¸‚":
            df_focus = df[df["Town"].astype(str) == selected].copy()
            if df_focus.empty:
                st.warning(f"{selected} ç›®å‰æ²’æœ‰å¯ç”¨é»ä½è³‡æ–™ã€‚")
                df_focus = df.copy()
            else:
                st.info(district_stats_line(df_focus, selected))
                fit_zoom = True
        else:
            df_focus = df.copy()
            st.caption("ç›®å‰é¡¯ç¤ºï¼šå…¨å¸‚é»ä½")
    else:
        df_focus = df.copy()
        st.warning("è³‡æ–™æœªæä¾›è¡Œæ”¿å€ï¼ˆTownï¼‰æ¬„ä½ï¼Œæš«ç„¡æ³•ä½¿ç”¨ä¸‹æ‹‰èšç„¦ã€‚")

    st.divider()

    st.subheader("åœ°åœ–ï¼ˆä¾ PM2.5 åˆ†ç´šä¸Šè‰²ï¼‰")
    render_map(df_focus, fit_zoom=fit_zoom)
    st.caption("æç¤ºï¼šæ»‘é¼ ç§»åˆ°é»ä½ä¸Šï¼Œå¯ç›´æ¥çœ‹åˆ° PM2.5ã€åˆ†ç´šã€æº«æ¿•åº¦ã€å»ºè­°ã€æ•æ„Ÿæ—ç¾¤æé†’èˆ‡åˆ†ç´šé–€æª»ã€‚")

    st.divider()
    with st.expander("è¡Œæ”¿å€æ‘˜è¦ï¼ˆå¹³å‡ / æœ€å¤§ / ä¸­ä½æ•¸ PM2.5ï¼‰", expanded=False):
        if dist_tbl.empty:
            st.info("ç›®å‰è³‡æ–™ç¼ºå°‘è¡Œæ”¿å€ï¼ˆTownï¼‰æˆ– PM2.5 æ¬„ä½ï¼Œæš«ç„¡æ³•ç”¢ç”Ÿè¡Œæ”¿å€æ‘˜è¦ã€‚")
        else:
            st.dataframe(dist_tbl, use_container_width=True)

    st.divider()
    with st.expander("å®Œæ•´è³‡æ–™è¡¨ï¼ˆé€²éšï¼šå¯æ’åºã€å¯æŸ¥è©¢ï¼‰", expanded=False):
        st.dataframe(df_focus, use_container_width=True, hide_index=True)
        st.caption(f"ç³»çµ±æŠ“å–æ™‚é–“ï¼š{fetch_time_str}ï½œè³‡æ–™è½åœ°ï¼š{CACHE_FILE}")

    with st.expander("æŠ€è¡“è³‡è¨Šï¼ˆå¯é¸ï¼‰", expanded=False):
        st.write("âœ… æœ¬æ¬¡å¯¦éš›ä½¿ç”¨çš„ APIï¼š")
        st.code(used_url)
        st.write("âœ… è³‡æ–™è½åœ°ï¼š")
        st.code(CACHE_FILE)
        st.caption("è¨»ï¼šæœ¬è³‡æ–™é›†æœªæä¾›è§€æ¸¬æ™‚é–“æˆ³ï¼›æœ¬é ä»¥ã€ç³»çµ±æŠ“å–æ™‚é–“ã€ä½œç‚ºæ›´æ–°åŸºæº–é¡¯ç¤ºã€‚")

else:
    st.subheader("åœ°åœ–ï¼ˆé»ä½åˆ†ä½ˆï¼šä¾ PM2.5 åˆ†ç´šä¸Šè‰²ï¼‰")
    render_map(df, fit_zoom=False)
    st.caption("æç¤ºï¼šæ»‘é¼ ç§»åˆ°é»ä½ä¸Šï¼Œå¯ç›´æ¥çœ‹åˆ° PM2.5ã€åˆ†ç´šã€æº«æ¿•åº¦ã€å»ºè­°ã€æ•æ„Ÿæ—ç¾¤æé†’èˆ‡åˆ†ç´šé–€æª»ã€‚")

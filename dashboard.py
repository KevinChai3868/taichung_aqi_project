# dashboard.py
# è‡ºä¸­å¸‚ç©ºå“å¾®ç’°å¢ƒå„€è¡¨æ¿ï¼ˆA2 å¤šé»ä½ï¼‰
# è§£æ³• Aï¼šé›²ç«¯ï¼ˆStreamlit Cloudï¼‰åªè®€ data/taichung_micro_latest.jsonï¼Œä¸ç›´æ¥æ‰“ APIï¼ˆé¿å… SSL æ†‘è­‰å•é¡Œï¼‰
# æœ¬æ©Ÿå¯é¸æ“‡æ€§æ‰“ APIï¼ˆä½†é è¨­ä¹Ÿä»ä»¥ JSON å¿«ç…§ç‚ºä¸»ï¼‰

import os
import json
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

# --- å¯é¸ï¼šæœ¬æ©Ÿæ‰éœ€è¦ requestsï¼ˆé›²ç«¯ä¸æœƒç”¨åˆ°ï¼Œrequirements æœ‰æ²’æœ‰ä¹Ÿä¸å½±éŸ¿ä¸»è¦åŠŸèƒ½ï¼‰ ---
try:
    import requests  # type: ignore
except Exception:
    requests = None  # noqa

# -----------------------------
# åŸºæœ¬è¨­å®š
# -----------------------------
st.set_page_config(
    page_title="è‡ºä¸­å¸‚ç©ºå“å¾®ç’°å¢ƒå„€è¡¨æ¿ï¼ˆA2 å¤šé»ä½ï¼‰",
    layout="wide",
    initial_sidebar_state="expanded",
)

APP_TITLE = "è‡ºä¸­å¸‚ç©ºå“å¾®ç’°å¢ƒå„€è¡¨æ¿ï¼ˆA2 å¤šé»ä½ï¼‰"
DATA_JSON_PATH = os.path.join("data", "taichung_micro_latest.json")

# ä½ ä¹‹å‰å˜—è©¦éçš„ API å€™é¸ï¼ˆä¿ç•™åœ¨ UI é¡¯ç¤ºä¾†æºï¼Œä½†é›²ç«¯ä¸æœƒçœŸçš„é€£ï¼‰
DEFAULT_API_CANDIDATES = [
    "https://datacenter.taichung.gov.tw/swagger/OpenData/33093aab-c094-4caf-9653-389ee511a618?limit=1000&offset=0",
    "https://datacenter.taichung.gov.tw/OpenData/33093aab-c094-4caf-9653-389ee511a618?limit=1000&offset=0",
    "https://datacenter.taichung.gov.tw/api/OpenData/33093aab-c094-4caf-9653-389ee511a618?limit=1000&offset=0",
    "https://datacenter.taichung.gov.tw/openapi/OpenData/33093aab-c094-4caf-9653-389ee511a618?limit=1000&offset=0",
]

# -----------------------------
# å·¥å…·ï¼šåˆ¤æ–·ç’°å¢ƒ
# -----------------------------
def is_streamlit_cloud() -> bool:
    """
    ç²—ç•¥åˆ¤æ–·æ˜¯å¦åœ¨ Streamlit Cloudã€‚
    - Streamlit Cloud å¸¸è¦‹ç’°å¢ƒè®Šæ•¸ï¼šSTREAMLIT_SHARING / STREAMLIT_CLOUD ç­‰ï¼ˆå¯èƒ½æœƒè®Šï¼‰
    - æˆ‘å€‘æ¡ã€Œä¿å®ˆç­–ç•¥ã€ï¼šåªè¦ä¸æ˜¯æ˜ç¢ºæœ¬æ©Ÿï¼Œå°±ç•¶ä½œé›²ç«¯ï¼Œé¿å…æ‰“ APIã€‚
    """
    for k in ["STREAMLIT_SHARING", "STREAMLIT_CLOUD", "STREAMLIT_RUNTIME_ENV"]:
        if os.getenv(k):
            return True
    # GitHub Codespaces / Replit ç­‰ä¹Ÿç•¶ä½œé›²ç«¯é¡ç’°å¢ƒï¼Œé¿å… SSL/ç¶²è·¯ä¸ç©©
    if os.getenv("CODESPACES") or os.getenv("REPL_ID"):
        return True
    # è‹¥ä½¿ç”¨è€…æœ‰é¡¯ç¤ºè¨­å®š LOCAL_RUN=1ï¼Œæ‰è¦–ç‚ºæœ¬æ©Ÿ
    if os.getenv("LOCAL_RUN") == "1":
        return False
    # é è¨­ä¿å®ˆï¼šè¦–ç‚ºé›²ç«¯
    return True


# -----------------------------
# å·¥å…·ï¼šPM2.5 åˆ†ç´šï¼ˆä½ ç•«é¢å·²åœ¨ç”¨çš„é–€æª»ï¼‰
# -----------------------------
def pm25_level(pm25: float) -> Tuple[str, str]:
    """
    å›å‚³ï¼šç­‰ç´šæ–‡å­—ã€å»ºè­°çŸ­èªï¼ˆçµ¦ä¸€èˆ¬æ°‘çœ¾å¯ç†è§£ï¼‰
    é–€æª»æ²¿ç”¨ä½ ç•«é¢ä¸Šçš„ç‰ˆæœ¬ï¼š
    <=15.4 è‰¯å¥½
    15.5â€“35.4 æ™®é€š
    35.5â€“54.4 æ•æ„Ÿæ—ç¾¤ç•™æ„
    >=54.5 ä¸å¥åº·
    """
    if pm25 <= 15.4:
        return "è‰¯å¥½", "å¯æ­£å¸¸æ´»å‹•ã€‚"
    if pm25 <= 35.4:
        return "æ™®é€š", "å¤šæ•¸äººå¯æ­£å¸¸æ´»å‹•ï¼›æ•æ„Ÿæ—ç¾¤ç•™æ„èº«é«”ç‹€æ³ã€‚"
    if pm25 <= 54.4:
        return "æ•æ„Ÿæ—ç¾¤ç•™æ„", "æ•æ„Ÿæ—ç¾¤å»ºè­°æ¸›å°‘æˆ¶å¤–åŠ‡çƒˆæ´»å‹•ã€‚"
    return "ä¸å¥åº·", "å»ºè­°æ¸›å°‘æˆ¶å¤–æ´»å‹•ï¼›æ•æ„Ÿæ—ç¾¤é¿å…å¤–å‡ºã€‚"


def pm25_color_tag(level: str) -> str:
    # æ–‡å­—æ¨™ç±¤ç”¨ï¼ˆä¸å¼·åˆ¶é¡è‰²ï¼Œé¿å…ä¸åŒç’°å¢ƒæ¸²æŸ“å·®ç•°ï¼‰
    return {
        "è‰¯å¥½": "ğŸŸ¢",
        "æ™®é€š": "ğŸŸ¡",
        "æ•æ„Ÿæ—ç¾¤ç•™æ„": "ğŸŸ ",
        "ä¸å¥åº·": "ğŸ”´",
    }.get(level, "âšª")


# -----------------------------
# å·¥å…·ï¼šè®€å– JSON
# -----------------------------
def load_json_snapshot(path: str) -> Dict[str, Any]:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def extract_records(obj: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    æ”¯æ´å…©ç¨®å¸¸è¦‹æ ¼å¼ï¼š
    1) {"records":[...]}
    2) ç›´æ¥å°±æ˜¯ list / æˆ– {"data":[...]}
    """
    if isinstance(obj, dict):
        if isinstance(obj.get("records"), list):
            return obj["records"]
        if isinstance(obj.get("data"), list):
            return obj["data"]
    if isinstance(obj, list):
        return obj
    return []


def normalize_df(records: List[Dict[str, Any]]) -> pd.DataFrame:
    """
    ç›¡é‡å®¹éŒ¯ï¼šä¸åŒè³‡æ–™é›†æ¬„ä½åå¯èƒ½ä¸åŒ
    ä½ ç›®å‰éœ€è¦çš„æ ¸å¿ƒæ¬„ä½ï¼š
    - ç¶“åº¦ã€ç·¯åº¦ï¼ˆlon/latï¼‰
    - PM2.5ï¼ˆpm25ï¼‰
    - æº«åº¦/æ¿•åº¦ï¼ˆtemp/humidityï¼‰å¯æœ‰å¯ç„¡
    - è¡Œæ”¿å€ï¼ˆdistrictï¼‰å¯æœ‰å¯ç„¡
    - é»ä½åç¨±ï¼ˆnameï¼‰å¯æœ‰å¯ç„¡
    - è§€æ¸¬æ™‚é–“ï¼ˆtimeï¼‰å¯æœ‰å¯ç„¡
    """
    df = pd.DataFrame(records).copy()

    # å°å¯«åŒ–æ¬„ä½ï¼Œæ–¹ä¾¿å°é½Š
    df.columns = [str(c).strip().lower() for c in df.columns]

    # æ¬„ä½åˆ¥åå°é½Š
    rename_map = {
        "longitude": "lon",
        "lng": "lon",
        "long": "lon",
        "ç¶“åº¦": "lon",
        "latitude": "lat",
        "ç·¯åº¦": "lat",
        "pm2_5": "pm25",
        "pm25": "pm25",
        "pm2.5": "pm25",
        "pm2_5_avg": "pm25",
        "temperature": "temp",
        "temp_c": "temp",
        "æº«åº¦": "temp",
        "humidity": "humidity",
        "rh": "humidity",
        "æ¿•åº¦": "humidity",
        "district": "district",
        "è¡Œæ”¿å€": "district",
        "area": "district",
        "sitename": "name",
        "site_name": "name",
        "é»ä½": "name",
        "name": "name",
        "time": "time",
        "timestamp": "time",
        "datatime": "time",
        "datetime": "time",
        "æ¸¬å®šæ™‚é–“": "time",
        "publishtime": "time",
        "publish_time": "time",
    }
    for k, v in rename_map.items():
        if k in df.columns and v not in df.columns:
            df = df.rename(columns={k: v})

    # è½‰æ•¸å­—æ¬„ä½
    for c in ["lon", "lat", "pm25", "temp", "humidity"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    # æ¸…æ‰æ²’æœ‰ç¶“ç·¯åº¦çš„é»
    if "lon" in df.columns and "lat" in df.columns:
        df = df.dropna(subset=["lon", "lat"])
    else:
        # æ²’æœ‰ç¶“ç·¯åº¦å°±å›å‚³ç©ºï¼Œé¿å…åœ°åœ–å ±éŒ¯
        return pd.DataFrame()

    # PM2.5 ç¼ºå€¼å°±å…ˆ dropï¼ˆåœ°åœ–èˆ‡æ’åéƒ½éœ€è¦ï¼‰
    if "pm25" in df.columns:
        df = df.dropna(subset=["pm25"])
    else:
        return pd.DataFrame()

    # åŠ ä¸Šåˆ†ç´š
    levels = df["pm25"].apply(lambda x: pm25_level(float(x))[0])
    advices = df["pm25"].apply(lambda x: pm25_level(float(x))[1])
    df["level"] = levels
    df["advice"] = advices
    df["level_tag"] = df["level"].apply(pm25_color_tag)

    # è£œè¶³ç¼ºæ¬„ä½
    for c in ["name", "district", "temp", "humidity", "time"]:
        if c not in df.columns:
            df[c] = None

    return df


def infer_latest_time(df: pd.DataFrame) -> Optional[str]:
    """
    å˜—è©¦å¾ time æ¬„ä½æ¨ä¼°æœ€æ–°æ™‚é–“ï¼Œè‹¥è³‡æ–™æœ¬èº«ä¸æä¾›ï¼Œå›å‚³ None
    """
    if "time" not in df.columns:
        return None
    # time å¯èƒ½æ˜¯å­—ä¸²ï¼šå˜—è©¦ parse
    s = df["time"].dropna().astype(str).str.strip()
    if s.empty:
        return None
    # å˜—è©¦å¤šç¨®æ ¼å¼
    parsed = pd.to_datetime(s, errors="coerce", utc=False)
    parsed = parsed.dropna()
    if parsed.empty:
        return None
    # å–æœ€å¤§
    t = parsed.max()
    # é¡¯ç¤ºç‚ºè‡ºç£å¸¸ç”¨æ ¼å¼
    return t.strftime("%Y-%m-%d %H:%M:%S")


# -----------------------------
# ï¼ˆæœ¬æ©Ÿå¯é¸ï¼‰æŠ“ APIï¼šé›²ç«¯ç›´æ¥ç¦æ­¢
# -----------------------------
def try_fetch_api(urls: List[str], timeout: int = 20) -> Dict[str, Any]:
    if requests is None:
        raise RuntimeError("requests æœªå®‰è£ï¼Œç„¡æ³•æŠ“ APIã€‚è«‹æ”¹ç”¨æœ¬æ©Ÿå¿«ç…§ JSONã€‚")

    last_err = None
    for u in urls:
        try:
            r = requests.get(u, timeout=timeout)
            r.raise_for_status()
            return {"ok": True, "url": u, "json": r.json()}
        except Exception as e:
            last_err = e
            continue
    raise RuntimeError(f"æ‰€æœ‰å€™é¸ API éƒ½å¤±æ•—ï¼Œæœ€å¾ŒéŒ¯èª¤ï¼š{last_err}")


# -----------------------------
# ç‰ˆé¢ï¼šSidebar
# -----------------------------
st.sidebar.markdown("## é¡¯ç¤ºæ¨¡å¼")
mode = st.sidebar.radio(
    "é¸æ“‡ç•«é¢",
    ["ä¸€èˆ¬æ°‘çœ¾ï¼ˆå¿«é€Ÿç†è§£ï¼‰", "å°ˆæ¥­äººå“¡ï¼ˆå®Œæ•´åˆ†æï¼‰"],
    index=0,
)

st.sidebar.markdown("---")
st.sidebar.markdown("## é€£ç·šè¨­å®š")

api_url_hint = st.sidebar.text_input(
    "API URLï¼ˆå¯ç•™ç©ºï¼‰",
    value="https://datacenter.taichung.gov.tw/â€¦",
    help="é›²ç«¯å±•ç¤ºç‰ˆä¸ç›´æ¥é€£ç·š APIï¼ˆé¿å… SSL å•é¡Œï¼‰ï¼Œæ­¤æ¬„ä½åƒ…ä½œç‚ºè³‡æ–™ä¾†æºèªªæ˜ã€‚",
)

api_key_masked = st.sidebar.text_input(
    "API Keyï¼ˆå¦‚éœ€ï¼Œå·²éš±è—ï¼‰",
    value="********",
    type="password",
    help="æœ¬å°ˆé¡Œé›²ç«¯å±•ç¤ºç‰ˆä¸ä½¿ç”¨ API Keyï¼›è‹¥ä½ æœ¬æ©Ÿéœ€è¦ï¼Œå¯åœ¨ .env æˆ– fetch_local.py ç®¡ç†ã€‚",
)

colA, colB = st.sidebar.columns(2)
btn_refresh = colA.button("ç«‹å³æ›´æ–°", use_container_width=True)
btn_clear = colB.button("æ¸…é™¤å¿«å–", use_container_width=True)

st.sidebar.markdown("---")
st.sidebar.markdown("## é¡¯ç¤ºé¸é …ï¼ˆå…±ç”¨ï¼‰")
only_geo = st.sidebar.checkbox("åªé¡¯ç¤ºæœ‰ç¶“ç·¯åº¦çš„é»ä½", value=True)
only_hot = st.sidebar.checkbox("åªé¡¯ç¤ºè¶…æ¨™é»ä½ï¼ˆPM2.5 > 35.4ï¼‰", value=False)
show_trend = st.sidebar.checkbox("é»ä½åŠå¾‘éš¨ PM2.5 è®ŠåŒ–", value=True)

topn = st.sidebar.slider("Top Nï¼ˆPM2.5ï¼‰", min_value=10, max_value=100, value=50, step=5)

st.sidebar.markdown("---")
st.sidebar.caption("ğŸ”’ é›²ç«¯å±•ç¤ºç‰ˆæ¡ç”¨è³‡æ–™å¿«ç…§ï¼ˆJSONï¼‰ï¼Œä¸å³æ™‚é€£ç·šæ”¿åºœ APIï¼Œä»¥ç¢ºä¿ç©©å®šæ€§èˆ‡å®‰å…¨æ€§ã€‚")

# æ¸…é™¤å¿«å–
if btn_clear:
    st.cache_data.clear()
    st.toast("å·²æ¸…é™¤å¿«å–", icon="ğŸ§¹")


# -----------------------------
# è®€å–è³‡æ–™ï¼ˆæ ¸å¿ƒï¼‰
# -----------------------------
@st.cache_data(ttl=60)
def load_data() -> Tuple[pd.DataFrame, Dict[str, Any]]:
    """
    è®€å–è³‡æ–™ç­–ç•¥ï¼ˆæœ€ç©©ï¼‰ï¼š
    1) è‹¥ data/taichung_micro_latest.json å­˜åœ¨ â†’ ç›´æ¥è®€ï¼ˆæœ¬æ©Ÿ/é›²ç«¯éƒ½èƒ½è·‘ï¼‰
    2) è‹¥ä¸å­˜åœ¨ï¼š
       - é›²ç«¯ï¼šç›´æ¥æç¤ºã€Œè«‹å…ˆæ¨é€ JSONã€
       - æœ¬æ©Ÿï¼šå¯é¸æ“‡å˜—è©¦æ‰“ APIï¼ˆä»ä¸å»ºè­°ï¼Œå›  SSL å¸¸ä¸ç©©ï¼‰
    """
    meta: Dict[str, Any] = {
        "source": "è‡ºä¸­å¸‚æ”¿åºœ OpenDataï¼ˆå¾®å‹æ„Ÿæ¸¬ï¼‰",
        "snapshot_path": DATA_JSON_PATH,
        "used": None,
        "used_url": None,
        "fetched_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }

    if os.path.exists(DATA_JSON_PATH):
        obj = load_json_snapshot(DATA_JSON_PATH)
        recs = extract_records(obj)
        df = normalize_df(recs)
        meta["used"] = "snapshot_json"
        return df, meta

    # JSON ä¸å­˜åœ¨ â†’ åˆ†æµ
    if is_streamlit_cloud():
        meta["used"] = "cloud_no_snapshot"
        return pd.DataFrame(), meta

    # æœ¬æ©Ÿæ‰å…è¨±å˜—è©¦ APIï¼ˆä½†ä½ å¯è¦–éœ€æ±‚é—œæ‰ï¼‰
    # è‹¥ä½ ä¸å¸Œæœ›æœ¬æ©Ÿä¹Ÿæ‰“ APIï¼Œå¯ç›´æ¥å›å‚³ç©º df
    # é€™è£¡é è¨­ï¼šæœ¬æ©Ÿæœƒå˜—è©¦ä¸€æ¬¡
    result = try_fetch_api(DEFAULT_API_CANDIDATES)
    obj = result["json"]
    recs = extract_records(obj)
    df = normalize_df(recs)
    meta["used"] = "api_local"
    meta["used_url"] = result["url"]
    return df, meta


df, meta = load_data()

# -----------------------------
# Header
# -----------------------------
st.title(APP_TITLE)
st.caption("è³‡æ–™ä¾†æºï¼šè‡ºä¸­å¸‚æ”¿åºœ OpenDataï¼ˆå¾®å‹æ„Ÿæ¸¬ï¼šPM2.5ï¼æº«åº¦ï¼æ¿•åº¦ï¼ç¶“ç·¯åº¦ï¼‰")

# ä½¿ç”¨æ–¹å¼æç¤º
st.success(
    "ä½¿ç”¨æ–¹å¼ï¼šå…ˆçœ‹ã€Œå¿«é€Ÿåˆ¤è®€ã€æŠ“é‡é» â†’ å†çœ‹åœ°åœ–å®šä½ï¼›å¯ç”¨ä¸‹æ‹‰é¸æ“‡è¡Œæ”¿å€èšç„¦æŸ¥çœ‹ï¼›è‹¥åªæƒ³çœ‹éœ€æ³¨æ„åœ°é»ï¼Œå‹¾é¸å·¦å´ã€Œåªé¡¯ç¤ºè¶…æ¨™é»ä½ã€ã€‚",
    icon="âœ…",
)

# -----------------------------
# è‹¥é›²ç«¯æ²’ snapshotï¼Œçµ¦æ˜ç¢ºæç¤ºï¼ˆä¸æ‰“ APIï¼Œä¸å ± SSLï¼‰
# -----------------------------
if df.empty:
    st.error(
        "ç›®å‰æ‰¾ä¸åˆ°è³‡æ–™å¿«ç…§ï¼ˆdata/taichung_micro_latest.jsonï¼‰ã€‚\n\n"
        "âœ… è§£æ³• Aï¼ˆå»ºè­°ï¼‰ï¼šè«‹åœ¨æœ¬æ©ŸåŸ·è¡Œ `python fetch_local.py` ç”¢ç”Ÿæœ€æ–° JSONï¼Œç„¶å¾Œ push åˆ° GitHubã€‚\n"
        "é›²ç«¯å±•ç¤ºç‰ˆå°‡è‡ªå‹•è®€å–è©² JSONï¼Œä¸ç›´æ¥é€£ç·š APIï¼ˆé¿å… SSL æ†‘è­‰å•é¡Œï¼‰ã€‚",
        icon="ğŸš«",
    )
    st.stop()


# -----------------------------
# ç¯©é¸
# -----------------------------
if only_geo:
    df = df.dropna(subset=["lon", "lat"])

if only_hot:
    df = df[df["pm25"] > 35.4]

# è¡Œæ”¿å€ä¸‹æ‹‰ï¼ˆå«ã€Œå…¨å¸‚ã€ï¼‰
districts = ["å…¨å¸‚"] + sorted([d for d in df["district"].dropna().unique().tolist() if str(d).strip() != ""])
st.markdown("### é¸æ“‡è¡Œæ”¿å€ï¼ˆèšç„¦æŸ¥çœ‹ï¼‰")
sel_dist = st.selectbox("è¡Œæ”¿å€", districts, index=0, label_visibility="collapsed")

if sel_dist != "å…¨å¸‚":
    df_view = df[df["district"] == sel_dist].copy()
else:
    df_view = df.copy()

# -----------------------------
# æŒ‡æ¨™å€ï¼šå¿«è¨Š / åˆ†ç´š
# -----------------------------
pm25_median = float(df_view["pm25"].median()) if not df_view.empty else 0.0
level_txt, advice_txt = pm25_level(pm25_median)

# æœ€æ–°æ™‚é–“ï¼ˆè³‡æ–™å…§æœ‰ time å°±ç”¨ï¼›å¦å‰‡é¡¯ç¤ºã€Œä»¥æŠ“å–æ™‚é–“ç‚ºæº–ã€ï¼‰
latest_time = infer_latest_time(df_view)
if latest_time is None:
    latest_time_display = f"{meta['fetched_at']}ï¼ˆæœ¬è³‡æ–™é›†æœªæä¾›è§€æ¸¬æ™‚é–“æ¬„ä½ï¼‰"
else:
    latest_time_display = latest_time

# å››å€‹ KPI
k1, k2, k3, k4 = st.columns(4)
k1.metric("é»ä½æ•¸ï¼ˆæ¯è£ç½®å–æœ€æ–°ä¸€ç­†ï¼‰", f"{len(df_view):,}")
k2.metric("PM2.5 ä¸­ä½æ•¸", f"{pm25_median:.1f}", f"{pm25_color_tag(level_txt)} {level_txt}")
k3.metric("PM2.5 æœ€å¤§å€¼", f"{float(df_view['pm25'].max()):.1f}")
k4.metric("è³‡æ–™æ™‚é–“ï¼ˆæœ€æ–°ï¼‰", latest_time_display)

# å¿«é€Ÿåˆ¤è®€
st.markdown("## å¿«é€Ÿåˆ¤è®€")
st.info(f"è‡ºä¸­å¸‚æ•´é«”ç©ºå“ä»¥ã€Œ{level_txt}ã€ç‚ºä¸»ï¼ˆPM2.5 ä¸­ä½æ•¸ {pm25_median:.1f}ï¼‰ã€‚{advice_txt}", icon="ğŸ§­")

# æé†’å€ï¼šä½ éœ€è¦ç•™æ„ä»€éº¼ï¼Ÿ
st.markdown("## ä½ éœ€è¦ç•™æ„ä»€éº¼ï¼Ÿ")
# ä»¥è¡Œæ”¿å€å…§ã€Œæœ€é«˜ PM2.5ã€æ’åºï¼ˆå– Top 3ï¼‰
tmp = df.copy()
tmp["district"] = tmp["district"].fillna("ï¼ˆæœªæä¾›è¡Œæ”¿å€ï¼‰")
grp = tmp.groupby("district", dropna=False).agg(
    max_pm25=("pm25", "max"),
    avg_pm25=("pm25", "mean"),
    cnt=("pm25", "count"),
).reset_index().sort_values("max_pm25", ascending=False)

top3 = grp.head(3)
lines = []
for _, r in top3.iterrows():
    lvl, adv = pm25_level(float(r["max_pm25"]))
    lines.append(
        f"- **{r['district']}**ï¼šæœ€é«˜ {r['max_pm25']:.1f}ï¼ˆå¹³å‡ {r['avg_pm25']:.1f}ï¼Œé»ä½ {int(r['cnt'])}ï¼‰"
        f"ã€€{pm25_color_tag(lvl)} {lvl}ï½œ{adv}"
    )
st.markdown("\n".join(lines))

# çœ‹åœ–å°æŠ„ï¼šåˆ†ç´šé–€æª»èˆ‡æ•æ„Ÿæ—ç¾¤æé†’ï¼ˆä½ è¦æ±‚çš„çŸ­èªï¼‰
st.markdown("## çœ‹åœ–å°æŠ„")
st.markdown(
    "- ğŸŸ¢ â‰¤15.4ï¼šè‰¯å¥½ã€€ã€€- ğŸŸ¡ 15.5â€“35.4ï¼šæ™®é€šã€€ã€€- ğŸŸ  35.5â€“54.4ï¼šæ•æ„Ÿæ—ç¾¤ç•™æ„ã€€ã€€- ğŸ”´ â‰¥54.5ï¼šä¸å¥åº·\n"
    "- åœ“é»è¶Šå¤§ä»£è¡¨ PM2.5 è¶Šé«˜ã€‚\n"
    "- **æ•æ„Ÿæ—ç¾¤æé†’**ï¼šå¦‚æœ‰ä¸é©ï¼Œè«‹æ¸›å°‘æˆ¶å¤–æ´»å‹•ä¸¦ç•™æ„èº«é«”ç‹€æ³ã€‚\n"
    f"- ç³»çµ±æŠ“å–æ™‚é–“ï¼š**{meta['fetched_at']}**ï¼ˆé›²ç«¯å±•ç¤ºç‰ˆæ¡ç”¨è³‡æ–™å¿«ç…§ï¼‰"
)

# -----------------------------
# åœ°åœ–ï¼ˆé»ä½åˆ†ä½ˆï¼‰
# -----------------------------
st.markdown("## åœ°åœ–ï¼ˆé»ä½åˆ†ä½ˆï¼šä¾ PM2.5 åˆ†ç´šä¸Šè‰²ï¼‰")

# tooltipï¼ˆæ›´å®Œæ•´ï¼šæº«åº¦/æ¿•åº¦/åˆ†ç´šå»ºè­°ï¼‰
def build_tooltip(row: pd.Series) -> str:
    name = row.get("name") if pd.notna(row.get("name")) else "ï¼ˆæœªå‘½åé»ä½ï¼‰"
    dist = row.get("district") if pd.notna(row.get("district")) else "ï¼ˆæœªæä¾›è¡Œæ”¿å€ï¼‰"
    pm = float(row.get("pm25", 0.0))
    lvl = row.get("level", "")
    adv = row.get("advice", "")
    t = row.get("temp")
    h = row.get("humidity")
    t_txt = f"{float(t):.1f}Â°C" if pd.notna(t) else "æœªæä¾›"
    h_txt = f"{float(h):.0f}%" if pd.notna(h) else "æœªæä¾›"
    return (
        f"{name}\n"
        f"è¡Œæ”¿å€ï¼š{dist}\n"
        f"PM2.5ï¼š{pm:.1f}ï¼ˆ{lvl}ï¼‰\n"
        f"æº«åº¦ï¼š{t_txt}ï½œæ¿•åº¦ï¼š{h_txt}\n"
        f"å»ºè­°ï¼š{adv}"
    )

df_map = df_view.copy()
df_map["tooltip"] = df_map.apply(build_tooltip, axis=1)

# é»ä½åŠå¾‘ï¼šå¯éš¨ PM2.5 è®ŠåŒ–ï¼ˆä½ è¦æ±‚çš„è‡ªå‹•ç¸®æ”¾æ„Ÿï¼‰
if show_trend:
    # åŸºç¤åŠå¾‘ + ä¾ pm25 æ‹‰ä¼¸ï¼ˆé™åˆ¶æœ€å¤§å€¼é¿å…çˆ†è¡¨ï¼‰
    df_map["radius"] = (df_map["pm25"].clip(lower=0, upper=200) / 2.5 + 40).clip(lower=40, upper=180)
else:
    df_map["radius"] = 60

# é¡è‰²åˆ†ç´šï¼šç”¨ level_tag å€åˆ†ï¼ˆstreamlit map åªèƒ½ç”¨ color éœ€æ­é… st.pydeckï¼‰
import pydeck as pdk  # æ”¾é€™è£¡é¿å…ä½  requirements ç¼º pydeck æ™‚å¤ªæ—©çˆ†

# é¡è‰²æ˜ å°„ï¼ˆRGBAï¼‰
COLOR_MAP = {
    "è‰¯å¥½": [0, 200, 120, 180],
    "æ™®é€š": [240, 200, 0, 180],
    "æ•æ„Ÿæ—ç¾¤ç•™æ„": [255, 140, 0, 180],
    "ä¸å¥åº·": [230, 60, 60, 180],
}

def color_of(level: str) -> List[int]:
    return COLOR_MAP.get(level, [120, 120, 120, 160])

df_map["color"] = df_map["level"].apply(color_of)

# è‡ªå‹•ç¸®æ”¾ï¼šç”¨é»ä½çš„å¹³å‡å€¼ä½œç‚ºä¸­å¿ƒ
center_lat = float(df_map["lat"].mean())
center_lon = float(df_map["lon"].mean())

layer = pdk.Layer(
    "ScatterplotLayer",
    data=df_map,
    get_position="[lon, lat]",
    get_fill_color="color",
    get_radius="radius",
    pickable=True,
    auto_highlight=True,
)

view_state = pdk.ViewState(latitude=center_lat, longitude=center_lon, zoom=11, pitch=0)

deck = pdk.Deck(
    layers=[layer],
    initial_view_state=view_state,
    tooltip={"text": "{tooltip}"},
)

st.pydeck_chart(deck, use_container_width=True)

# -----------------------------
# è¡¨æ ¼å€ï¼šTop N é«˜é»ä½ + å…¨è¡¨
# -----------------------------
st.markdown(f"## PM2.5 å‰ {topn} é«˜é»ä½")
df_top = df_view.sort_values("pm25", ascending=False).head(topn).copy()
show_cols = ["level_tag", "name", "district", "pm25", "temp", "humidity", "level", "advice", "time", "lon", "lat"]
show_cols = [c for c in show_cols if c in df_top.columns]
st.dataframe(df_top[show_cols], use_container_width=True, height=380)

# å°ˆæ¥­æ¨¡å¼ï¼šé¡¯ç¤ºæ›´å¤šçµ±è¨ˆæ‘˜è¦
if mode.startswith("å°ˆæ¥­"):
    st.markdown("## å°ˆæ¥­æ‘˜è¦ï¼ˆçµ±è¨ˆï¼‰")
    c1, c2, c3 = st.columns(3)
    c1.metric("PM2.5 å¹³å‡", f"{float(df_view['pm25'].mean()):.1f}")
    c2.metric("PM2.5 75 åˆ†ä½æ•¸", f"{float(df_view['pm25'].quantile(0.75)):.1f}")
    c3.metric("è¶…æ¨™é»ä½æ•¸ï¼ˆ>35.4ï¼‰", f"{int((df_view['pm25'] > 35.4).sum()):,}")

    st.markdown("### è¡Œæ”¿å€åˆ†ä½ˆï¼ˆä¾æœ€é«˜ PM2.5 æ’åºï¼‰")
    st.dataframe(grp.head(20), use_container_width=True)

# ä¾†æºè³‡è¨Š
st.markdown("---")
st.caption(
    f"è³‡æ–™ä¾†æºï¼š{meta['source']}ï½œè®€å–æ–¹å¼ï¼š{meta['used']}ï½œå¿«ç…§è·¯å¾‘ï¼š{meta['snapshot_path']}"
)

# dashboard.py
# è‡ºä¸­å¸‚ç©ºå“å¾®ç’°å¢ƒå„€è¡¨æ¿ï¼ˆA2 å¤šé»ä½ï¼‰
# è§£æ³• Aï¼ˆå›ºå®šï¼‰ï¼šé›²ç«¯åªè®€ data/taichung_micro_latest.jsonï¼Œä¸ç›´æ¥é€£ç·š APIï¼ˆé¿å… SSL æ†‘è­‰å•é¡Œï¼‰
# ===== DEBUG: Cloud æª”æ¡ˆç›¤é»ï¼ˆæš«æ™‚ç”¨ï¼Œç¢ºèªå®Œå°±åˆªï¼‰=====
import os
import streamlit as st

st.write("DEBUG cwd =", os.getcwd())
st.write("DEBUG root files =", os.listdir("."))

if os.path.exists("data"):
    st.write("DEBUG data/ files =", os.listdir("data"))
else:
    st.write("DEBUG data/ folder NOT found")

st.write("DEBUG exists data/taichung_micro_latest.json =",
         os.path.exists(os.path.join("data", "taichung_micro_latest.json")))
# =====================================================

import os
import json
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st
import pydeck as pdk

# -----------------------------
# åŸºæœ¬è¨­å®š
# -----------------------------
st.set_page_config(
    page_title="è‡ºä¸­å¸‚ç©ºå“å¾®ç’°å¢ƒå„€è¡¨æ¿ï¼ˆA2 å¤šé»ä½ï¼‰",
    layout="wide",
    initial_sidebar_state="expanded",
)

APP_TITLE = "è‡ºä¸­å¸‚ç©ºå“å¾®ç’°å¢ƒå„€è¡¨æ¿ï¼ˆA2 å¤šé»ä½ï¼‰"
DATA_JSON_PATH = os.path.join("data", "taichung_micro_latest.json")


# -----------------------------
# PM2.5 åˆ†ç´šï¼ˆä¾ä½ ç•«é¢é–€æª»ï¼‰
# -----------------------------
def pm25_level(pm25: float) -> Tuple[str, str]:
    """
    é–€æª»ï¼ˆèˆ‡ä½ ç•«é¢ä¸€è‡´ï¼‰ï¼š
    <=15.4 è‰¯å¥½
    15.5â€“35.4 æ™®é€š
    35.5â€“54.4 æ•æ„Ÿæ—ç¾¤ç•™æ„
    >=54.5 ä¸å¥åº·
    """
    if pm25 <= 15.4:
        return "è‰¯å¥½", "å¯æ­£å¸¸æ´»å‹•ã€‚"
    if pm25 <= 35.4:
        return "æ™®é€š", "å¤šæ•¸äººå¯æ­£å¸¸æ´»å‹•ï¼›æ•æ„Ÿæ—ç¾¤ç•™æ„èº«é«”ç‹€æ³ã€‚"
    if pm25 <= 54.4:
        return "æ•æ„Ÿæ—ç¾¤ç•™æ„", "æ•æ„Ÿæ—ç¾¤å»ºè­°æ¸›å°‘æˆ¶å¤–åŠ‡çƒˆæ´»å‹•ã€‚"
    return "ä¸å¥åº·", "å»ºè­°æ¸›å°‘æˆ¶å¤–æ´»å‹•ï¼›æ•æ„Ÿæ—ç¾¤é¿å…å¤–å‡ºã€‚"


def pm25_tag(level: str) -> str:
    return {"è‰¯å¥½": "ğŸŸ¢", "æ™®é€š": "ğŸŸ¡", "æ•æ„Ÿæ—ç¾¤ç•™æ„": "ğŸŸ ", "ä¸å¥åº·": "ğŸ”´"}.get(level, "âšª")


COLOR_MAP = {
    "è‰¯å¥½": [0, 200, 120, 180],
    "æ™®é€š": [240, 200, 0, 180],
    "æ•æ„Ÿæ—ç¾¤ç•™æ„": [255, 140, 0, 180],
    "ä¸å¥åº·": [230, 60, 60, 180],
}
def color_of(level: str) -> List[int]:
    return COLOR_MAP.get(level, [120, 120, 120, 160])


# -----------------------------
# JSON è®€å–èˆ‡æ­£è¦åŒ–
# -----------------------------
def load_json_snapshot(path: str) -> Dict[str, Any]:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def extract_records(obj: Any) -> List[Dict[str, Any]]:
    """
    æ›´å¼·å¥çš„ records èƒå–ï¼š
    æ”¯æ´ï¼š
    1) {"records":[...]}
    2) {"data":[...]} / {"data":{"records":[...]}}
    3) {"result":{"records":[...]}}
    4) {"response":{"records":[...]}}
    5) ç›´æ¥å°±æ˜¯ list
    """
    if obj is None:
        return []

    # ç›´æ¥ list
    if isinstance(obj, list):
        return obj

    if not isinstance(obj, dict):
        return []

    # ç›´æ¥ records / data
    if isinstance(obj.get("records"), list):
        return obj["records"]
    if isinstance(obj.get("data"), list):
        return obj["data"]

    # å¸¸è¦‹å·¢ç‹€ï¼šresult/response/data è£¡çš„ records
    for k in ["result", "response", "data"]:
        v = obj.get(k)
        if isinstance(v, dict) and isinstance(v.get("records"), list):
            return v["records"]

    return []


def normalize_df(records: List[Dict[str, Any]]) -> pd.DataFrame:
    df = pd.DataFrame(records).copy()
    if df.empty:
        return df

    df.columns = [str(c).strip().lower() for c in df.columns]
    
        "coordinatelatitude": "lat",
        "coordinatelongitude": "lon",
        "hum": "humidity",
        "town": "district",
        "landmark": "name",

    rename_map = {
        "longitude": "lon",
        "lng": "lon",
        "long": "lon",
        "ç¶“åº¦": "lon",
        "latitude": "lat",
        "ç·¯åº¦": "lat",
        "pm2_5": "pm25",
        "pm2.5": "pm25",
        "pm25": "pm25",
        "pm2_5_avg": "pm25",
        "temperature": "temp",
        "temp_c": "temp",
        "æº«åº¦": "temp",
        "humidity": "humidity",
        "rh": "humidity",
        "æ¿•åº¦": "humidity",
        "district": "district",
        "è¡Œæ”¿å€": "district",
        "area": "district",
        "sitename": "name",
        "site_name": "name",
        "é»ä½": "name",
        "name": "name",
        "time": "time",
        "timestamp": "time",
        "datatime": "time",
        "datetime": "time",
        "æ¸¬å®šæ™‚é–“": "time",
        "publishtime": "time",
        "publish_time": "time",
    }

    for k, v in rename_map.items():
        if k in df.columns and v not in df.columns:
            df = df.rename(columns={k: v})

    # è½‰æ•¸å­—æ¬„ä½
    for c in ["lon", "lat", "pm25", "temp", "humidity"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    # å¿…è¦æ¬„ä½æª¢æŸ¥
    if "lon" not in df.columns or "lat" not in df.columns or "pm25" not in df.columns:
        return pd.DataFrame()

    df = df.dropna(subset=["lon", "lat", "pm25"]).copy()

    # è£œæ¬„ä½
    for c in ["name", "district", "temp", "humidity", "time"]:
        if c not in df.columns:
            df[c] = None

    # åˆ†ç´šèˆ‡å»ºè­°
    df["level"] = df["pm25"].apply(lambda x: pm25_level(float(x))[0])
    df["advice"] = df["pm25"].apply(lambda x: pm25_level(float(x))[1])
    df["level_tag"] = df["level"].apply(pm25_tag)
    df["color"] = df["level"].apply(color_of)

    return df


def infer_latest_time_from_timecol(df: pd.DataFrame) -> Optional[str]:
    if "time" not in df.columns:
        return None
    s = df["time"].dropna().astype(str).str.strip()
    if s.empty:
        return None
    parsed = pd.to_datetime(s, errors="coerce")
    parsed = parsed.dropna()
    if parsed.empty:
        return None
    return parsed.max().strftime("%Y-%m-%d %H:%M:%S")


def file_mtime_str(path: str) -> Optional[str]:
    try:
        ts = os.path.getmtime(path)
        return datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return None


# -----------------------------
# Sidebar
# -----------------------------
st.sidebar.markdown("## é¡¯ç¤ºæ¨¡å¼")
mode = st.sidebar.radio(
    "é¸æ“‡ç•«é¢",
    ["ä¸€èˆ¬æ°‘çœ¾ï¼ˆå¿«é€Ÿç†è§£ï¼‰", "å°ˆæ¥­äººå“¡ï¼ˆå®Œæ•´åˆ†æï¼‰"],
    index=0,
)

st.sidebar.markdown("---")
st.sidebar.markdown("## é€£ç·šè¨­å®šï¼ˆå±•ç¤ºç”¨ï¼‰")

api_url_hint = st.sidebar.text_input(
    "API URLï¼ˆå±•ç¤ºç”¨ï¼Œå¯ç•™ç©ºï¼‰",
    value="https://datacenter.taichung.gov.tw/â€¦",
    help="æœ¬å„€è¡¨æ¿é›²ç«¯å±•ç¤ºç‰ˆä¸ç›´æ¥é€£ç·š APIï¼Œé¿å… SSL/ç¶²è·¯ä¸ç©©ï¼›è³‡æ–™ç”±æœ¬æ©Ÿ fetch_local.py ç”¢ç”Ÿ JSON å¿«ç…§å¾Œæ¨é€ã€‚",
)

api_key_masked = st.sidebar.text_input(
    "API Keyï¼ˆå¦‚éœ€ï¼Œå·²éš±è—ï¼‰",
    value="********",
    type="password",
    help="é›²ç«¯å±•ç¤ºç‰ˆä¸ä½¿ç”¨ API Keyï¼›æ­¤æ¬„ä½åƒ…ç‚ºå¢åŠ å¯ä¿¡åº¦/è®“è®€è€…ç†è§£ã€Œå¯æ”¯æ´éœ€è¦ Key çš„è³‡æ–™æºã€ã€‚",
)

colA, colB = st.sidebar.columns(2)
btn_refresh = colA.button("ç«‹å³æ›´æ–°ï¼ˆé‡æ–°è®€å–ï¼‰", use_container_width=True)
btn_clear = colB.button("æ¸…é™¤å¿«å–", use_container_width=True)

st.sidebar.markdown("---")
st.sidebar.markdown("## é¡¯ç¤ºé¸é …ï¼ˆå…±ç”¨ï¼‰")
only_geo = st.sidebar.checkbox("åªé¡¯ç¤ºæœ‰ç¶“ç·¯åº¦çš„é»ä½", value=True)
only_hot = st.sidebar.checkbox("åªé¡¯ç¤ºè¶…æ¨™é»ä½ï¼ˆPM2.5 > 35.4ï¼‰", value=False)
show_radius = st.sidebar.checkbox("é»ä½åŠå¾‘éš¨ PM2.5 è®ŠåŒ–ï¼ˆè‡ªå‹•ç¸®æ”¾æ„Ÿï¼‰", value=True)
topn = st.sidebar.slider("Top Nï¼ˆPM2.5ï¼‰", 10, 100, 50, 5)

st.sidebar.markdown("---")
st.sidebar.caption("ğŸ”’ é›²ç«¯å›ºå®šåªè®€ JSON å¿«ç…§ï¼Œä¸é€£ç·šæ”¿åºœ APIï¼ˆé¿å… SSL æ†‘è­‰å•é¡Œï¼Œç©©å®šå±•ç¤ºï¼‰ã€‚")

if btn_clear:
    st.cache_data.clear()
    st.toast("å·²æ¸…é™¤å¿«å–", icon="ğŸ§¹")

if btn_refresh:
    st.cache_data.clear()
    st.toast("å·²é‡æ–°è®€å–ï¼ˆæ¸…é™¤å¿«å–å¾Œè¼‰å…¥ï¼‰", icon="ğŸ”„")


# -----------------------------
# è®€è³‡æ–™ï¼ˆæ ¸å¿ƒï¼šåªè®€ JSONï¼‰
# -----------------------------
@st.cache_data(ttl=60)
def load_data_snapshot() -> Tuple[pd.DataFrame, Dict[str, Any]]:
    meta: Dict[str, Any] = {
        "source": "è‡ºä¸­å¸‚æ”¿åºœ OpenDataï¼ˆå¾®å‹æ„Ÿæ¸¬ï¼‰",
        "snapshot_path": DATA_JSON_PATH,
        "used": "snapshot_json_only",
        "loaded_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "snapshot_mtime": file_mtime_str(DATA_JSON_PATH),
        "snapshot_fetched_at": None,  # è‹¥ fetch_local.py æœ‰å¯«å…¥ fetched_atï¼Œæˆ‘å€‘æœƒæŠ“
    }

    if not os.path.exists(DATA_JSON_PATH):
        return pd.DataFrame(), meta

    obj = load_json_snapshot(DATA_JSON_PATH)

    # è‹¥ fetch_local.py æœ‰å¯« meta æ¬„ä½ï¼ˆä¾‹å¦‚ fetched_atï¼‰ï¼Œé€™è£¡å¯è®€å‡ºä¾†
    if isinstance(obj, dict):
        # å¸¸è¦‹ï¼š{"fetched_at":"...","records":[...]}
        if isinstance(obj.get("fetched_at"), str):
            meta["snapshot_fetched_at"] = obj["fetched_at"]
        if isinstance(obj.get("meta"), dict) and isinstance(obj["meta"].get("fetched_at"), str):
            meta["snapshot_fetched_at"] = obj["meta"]["fetched_at"]

    records = extract_records(obj)
    df = normalize_df(records)
    return df, meta


df, meta = load_data_snapshot()

# -----------------------------
# Header
# -----------------------------
st.title(APP_TITLE)
st.caption("è³‡æ–™ä¾†æºï¼šè‡ºä¸­å¸‚æ”¿åºœ OpenDataï¼ˆå¾®å‹æ„Ÿæ¸¬ï¼šPM2.5ï¼æº«åº¦ï¼æ¿•åº¦ï¼ç¶“ç·¯åº¦ï¼‰")

st.success(
    "ä½¿ç”¨æ–¹å¼ï¼šå…ˆçœ‹ã€Œå¿«é€Ÿåˆ¤è®€ã€æŠ“é‡é» â†’ å†çœ‹åœ°åœ–å®šä½ï¼›ç”¨ä¸‹æ‹‰é¸æ“‡è¡Œæ”¿å€èšç„¦ï¼›åªæƒ³çœ‹éœ€æ³¨æ„åœ°é»å¯å‹¾é¸ã€Œåªé¡¯ç¤ºè¶…æ¨™é»ä½ã€ã€‚",
    icon="âœ…",
)

# è‹¥æ²’æœ‰ JSONï¼Œçµ¦æ˜ç¢ºæç¤ºï¼ˆä¸å ± SSLï¼Œä¸æ‰“ APIï¼‰
if df.empty:
    st.error(
        f"å·²è®€åˆ° JSON æª”ï¼Œä½†è³‡æ–™è§£æå¾Œç‚ºç©ºï¼ˆdf.empty=Trueï¼‰ã€‚\n\n"
        f"âœ… æª”æ¡ˆå­˜åœ¨ï¼š{DATA_JSON_PATH}\n"
        f"â— ä»£è¡¨å•é¡Œä¸æ˜¯ã€Œæ²’æª”æ¡ˆã€ï¼Œè€Œæ˜¯ã€ŒJSON å…§å®¹æ¬„ä½ç„¡æ³•å°æ‡‰ã€\n\n"
        f"è«‹ç¢ºèª JSON å…§æ˜¯å¦åŒ…å«ï¼šç¶“åº¦ã€ç·¯åº¦ã€PM2.5ï¼ˆåç¨±å¯èƒ½ä¸åŒï¼‰ã€‚",
        icon="ğŸš«",
    )
    st.stop()

# -----------------------------
# ç¯©é¸ï¼šè¡Œæ”¿å€ä¸‹æ‹‰
# -----------------------------
if only_geo:
    df = df.dropna(subset=["lon", "lat"])

if only_hot:
    df = df[df["pm25"] > 35.4]

df["district"] = df["district"].fillna("ï¼ˆæœªæä¾›è¡Œæ”¿å€ï¼‰")
df["name"] = df["name"].fillna("ï¼ˆæœªå‘½åé»ä½ï¼‰")

districts = ["å…¨å¸‚"] + sorted([d for d in df["district"].unique().tolist() if str(d).strip() != ""])
st.markdown("### é¸æ“‡è¡Œæ”¿å€ï¼ˆèšç„¦æŸ¥çœ‹ï¼‰")
sel_dist = st.selectbox("è¡Œæ”¿å€", districts, index=0, label_visibility="collapsed")

df_view = df.copy()
if sel_dist != "å…¨å¸‚":
    df_view = df[df["district"] == sel_dist].copy()

# -----------------------------
# KPI èˆ‡æ™‚é–“ï¼ˆä¸å†é¡¯ç¤ºæœªçŸ¥ï¼‰
# -----------------------------
pm25_median = float(df_view["pm25"].median()) if not df_view.empty else 0.0
level_txt, advice_txt = pm25_level(pm25_median)

latest_from_timecol = infer_latest_time_from_timecol(df_view)

# é¡¯ç¤ºå„ªå…ˆé †åºï¼š
# 1) timeæ¬„ä½æ¨å¾—çš„æœ€æ–°æ™‚é–“
# 2) snapshot_fetched_atï¼ˆfetch_local.pyå¯«å…¥ï¼‰
# 3) æª”æ¡ˆæœ€å¾Œä¿®æ”¹æ™‚é–“ snapshot_mtime
# 4) loaded_atï¼ˆè¼‰å…¥æ™‚é–“ï¼‰
if latest_from_timecol:
    latest_time_display = latest_from_timecol + "ï¼ˆè³‡æ–™æ¬„ä½ time æ¨å¾—ï¼‰"
elif meta.get("snapshot_fetched_at"):
    latest_time_display = str(meta["snapshot_fetched_at"]) + "ï¼ˆå¿«ç…§ç”¢ç”Ÿæ™‚é–“ï¼‰"
elif meta.get("snapshot_mtime"):
    latest_time_display = str(meta["snapshot_mtime"]) + "ï¼ˆæª”æ¡ˆæœ€å¾Œä¿®æ”¹æ™‚é–“ï¼‰"
else:
    latest_time_display = str(meta["loaded_at"]) + "ï¼ˆè¼‰å…¥æ™‚é–“ï¼‰"

k1, k2, k3, k4 = st.columns(4)
k1.metric("é»ä½æ•¸ï¼ˆæ¯è£ç½®å–æœ€æ–°ä¸€ç­†ï¼‰", f"{len(df_view):,}")
k2.metric("PM2.5 ä¸­ä½æ•¸", f"{pm25_median:.1f}", f"{pm25_tag(level_txt)} {level_txt}")
k3.metric("PM2.5 æœ€å¤§å€¼", f"{float(df_view['pm25'].max()):.1f}")
k4.metric("è³‡æ–™æ™‚é–“ï¼ˆæœ€æ–°ï¼‰", latest_time_display)

# -----------------------------
# ä¸€èˆ¬æ°‘çœ¾ï¼šå¿«é€Ÿåˆ¤è®€æ–‡å­—èªªæ˜
# -----------------------------
st.markdown("## å¿«é€Ÿåˆ¤è®€")
st.info(f"ç›®å‰ {sel_dist} æ•´é«”ç©ºå“ä»¥ã€Œ{level_txt}ã€ç‚ºä¸»ï¼ˆPM2.5 ä¸­ä½æ•¸ {pm25_median:.1f}ï¼‰ã€‚{advice_txt}", icon="ğŸ§­")

st.markdown("## ä½ éœ€è¦ç•™æ„ä»€éº¼ï¼Ÿ")
grp = (
    df.groupby("district", dropna=False)
    .agg(max_pm25=("pm25", "max"), avg_pm25=("pm25", "mean"), cnt=("pm25", "count"))
    .reset_index()
    .sort_values("max_pm25", ascending=False)
)
top3 = grp.head(3)

lines = []
for _, r in top3.iterrows():
    lvl, adv = pm25_level(float(r["max_pm25"]))
    lines.append(
        f"- **{r['district']}**ï¼šæœ€é«˜ {r['max_pm25']:.1f}ï¼ˆå¹³å‡ {r['avg_pm25']:.1f}ï¼Œé»ä½ {int(r['cnt'])}ï¼‰"
        f"ã€€{pm25_tag(lvl)} {lvl}ï½œ{adv}"
    )
st.markdown("\n".join(lines))

st.markdown("## çœ‹åœ–å°æŠ„")
st.markdown(
    "- ğŸŸ¢ â‰¤15.4ï¼šè‰¯å¥½ã€€ã€€- ğŸŸ¡ 15.5â€“35.4ï¼šæ™®é€šã€€ã€€- ğŸŸ  35.5â€“54.4ï¼šæ•æ„Ÿæ—ç¾¤ç•™æ„ã€€ã€€- ğŸ”´ â‰¥54.5ï¼šä¸å¥åº·\n"
    "- åœ“é»è¶Šå¤§ä»£è¡¨ PM2.5 è¶Šé«˜ã€‚\n"
    "- **æ•æ„Ÿæ—ç¾¤æé†’**ï¼šå¦‚æœ‰ä¸é©ï¼Œè«‹æ¸›å°‘æˆ¶å¤–æ´»å‹•ä¸¦ç•™æ„èº«é«”ç‹€æ³ã€‚\n"
    f"- æœ¬æ¬¡é¡¯ç¤ºæ™‚é–“ï¼š**{latest_time_display}**"
)

# -----------------------------
# åœ°åœ–ï¼šè‡ªå‹•ç¸®æ”¾ä¸­å¿ƒ + hover tooltipï¼ˆæº«åº¦/æ¿•åº¦/å»ºè­°ï¼‰
# -----------------------------
st.markdown("## åœ°åœ–ï¼ˆé»ä½åˆ†ä½ˆï¼šä¾ PM2.5 åˆ†ç´šä¸Šè‰²ï¼‰")

def build_tooltip(row: pd.Series) -> str:
    pm = float(row.get("pm25", 0.0))
    lvl = row.get("level", "")
    adv = row.get("advice", "")
    t = row.get("temp")
    h = row.get("humidity")
    t_txt = f"{float(t):.1f}Â°C" if pd.notna(t) else "æœªæä¾›"
    h_txt = f"{float(h):.0f}%" if pd.notna(h) else "æœªæä¾›"
    return (
        f"{row.get('name','ï¼ˆæœªå‘½åé»ä½ï¼‰')}\n"
        f"è¡Œæ”¿å€ï¼š{row.get('district','ï¼ˆæœªæä¾›è¡Œæ”¿å€ï¼‰')}\n"
        f"PM2.5ï¼š{pm:.1f}ï¼ˆ{lvl}ï¼‰\n"
        f"æº«åº¦ï¼š{t_txt}ï½œæ¿•åº¦ï¼š{h_txt}\n"
        f"å»ºè­°ï¼š{adv}"
    )

df_map = df_view.copy()
df_map["tooltip"] = df_map.apply(build_tooltip, axis=1)

if show_radius:
    df_map["radius"] = (df_map["pm25"].clip(0, 200) / 2.5 + 40).clip(40, 180)
else:
    df_map["radius"] = 60

center_lat = float(df_map["lat"].mean())
center_lon = float(df_map["lon"].mean())

layer = pdk.Layer(
    "ScatterplotLayer",
    data=df_map,
    get_position="[lon, lat]",
    get_fill_color="color",
    get_radius="radius",
    pickable=True,
    auto_highlight=True,
)

# zoom ä¸å¯«æ­»å¤ªæ­»ï¼šä¾é»ä½ç¯„åœç•¥å¾®èª¿æ•´
# ç°¡åŒ–ç­–ç•¥ï¼šå…¨å¸‚é è¨­ 11ï¼Œç‰¹å®šè¡Œæ”¿å€ç•¥æ”¾å¤§
zoom = 11 if sel_dist == "å…¨å¸‚" else 12

deck = pdk.Deck(
    layers=[layer],
    initial_view_state=pdk.ViewState(latitude=center_lat, longitude=center_lon, zoom=zoom, pitch=0),
    tooltip={"text": "{tooltip}"},
)

st.pydeck_chart(deck, use_container_width=True)

# -----------------------------
# è¡¨æ ¼ï¼šTop N +ï¼ˆå°ˆæ¥­æ¨¡å¼ï¼‰è¡Œæ”¿å€å½™æ•´è¡¨
# -----------------------------
st.markdown(f"## PM2.5 å‰ {topn} é«˜é»ä½")
df_top = df_view.sort_values("pm25", ascending=False).head(topn).copy()

show_cols = ["level_tag", "name", "district", "pm25", "temp", "humidity", "level", "advice", "time", "lon", "lat"]
show_cols = [c for c in show_cols if c in df_top.columns]
st.dataframe(df_top[show_cols], use_container_width=True, height=380)

if mode.startswith("å°ˆæ¥­"):
    st.markdown("## å°ˆæ¥­æ‘˜è¦ï¼ˆçµ±è¨ˆï¼‰")
    c1, c2, c3 = st.columns(3)
    c1.metric("PM2.5 å¹³å‡", f"{float(df_view['pm25'].mean()):.1f}")
    c2.metric("PM2.5 75 åˆ†ä½æ•¸", f"{float(df_view['pm25'].quantile(0.75)):.1f}")
    c3.metric("è¶…æ¨™é»ä½æ•¸ï¼ˆ>35.4ï¼‰", f"{int((df_view['pm25'] > 35.4).sum()):,}")

    st.markdown("### è¡Œæ”¿å€åˆ†ä½ˆï¼ˆä¾æœ€é«˜ PM2.5 æ’åºï¼‰")
    st.dataframe(grp.head(30), use_container_width=True)

# -----------------------------
# Footer
# -----------------------------
st.markdown("---")
st.caption(
    f"è³‡æ–™ä¾†æºï¼š{meta.get('source')}ï½œè®€å–æ–¹å¼ï¼š{meta.get('used')}ï½œå¿«ç…§ï¼š{meta.get('snapshot_path')}ï½œè¼‰å…¥æ™‚é–“ï¼š{meta.get('loaded_at')}"
)





